{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Classificação de produtos pela categoria.\n",
                "\n",
                "Neste notebook exploramos diferentes estratégias de ML/DL para classificar produtos em suas categorias."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import os\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
                "from sklearn.metrics import accuracy_score, f1_score\n",
                "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.base import clone\n",
                "\n",
                "from gensim.models.doc2vec import Doc2Vec\n",
                "from gensim.models.word2vec import Word2Vec\n",
                "from gensim.models.fasttext import FastText\n",
                "\n",
                "import string\n",
                "from nltk.tokenize import word_tokenize\n",
                "from nltk.corpus import stopwords"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "headers = [\"p_id\", \"p_title\", \"vendor_id\", \"cluster_id\", \"cluster_title\", \"cat_id\", \"cat_title\"]\n",
                "df = pd.read_csv('datasets/pricerunner_aggregate.csv', header=0, names = headers)\n",
                "#df = df[df.cat_id == 2612]\n",
                "df.head()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "df.info"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Construção de atributos (Features)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Remove pontos, números e stopwords.\n",
                "def clean_text(sentences):\n",
                "\n",
                "    stop_words = {word: True for word in stopwords.words(\"english\")}\n",
                "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
                "    tokens = []\n",
                "    for text in sentences:\n",
                "        words = []\n",
                "        for word in text.lower().translate(table).split():\n",
                "            #if word not in stop_words:\n",
                "            if not word.isnumeric() and word not in stop_words:\n",
                "                words.append(word)\n",
                "        tokens.append(words)\n",
                "    return tokens\n",
                "\n",
                "# Carrega modelo Word2Vec.\n",
                "def get_w2v(tokens, model_path=\"models/w2v\", params=None, rebuild=False, save_model=True):\n",
                "\n",
                "    if os.path.exists(model_path) and not rebuild:\n",
                "        return Word2Vec.load(model_path)\n",
                "\n",
                "    if params is not None:\n",
                "        model = Word2Vec(\n",
                "            sentences=tokens, vector_size=params[\"vector_size\"], epochs=params[\"epochs\"]\n",
                "        )\n",
                "    else:\n",
                "        model = Word2Vec(sentences=tokens, workers=15)\n",
                "\n",
                "    if save_model:\n",
                "        if params is not None:\n",
                "            keys = list(params.keys())\n",
                "            keys.sort()\n",
                "            sufix = \"_\".join([key + \"-\" + str(params[key]) for key in keys])\n",
                "        else:\n",
                "            sufix = \"default.model\"\n",
                "        output = \"models/w2v_\" + sufix + \".model\"\n",
                "        model.save(output)\n",
                "\n",
                "    return model\n",
                "\n",
                "# Transforma dados em vetor com o modelo word2vec.\n",
                "def w2v_transform(sentences, w2v):\n",
                "\n",
                "    vecs = []\n",
                "    for s in sentences:\n",
                "        vecs_t = []\n",
                "        for token in s:\n",
                "            if token in w2v.wv:\n",
                "                vecs_t.append(w2v.wv[token])\n",
                "        if vecs_t:\n",
                "            vecs.append(np.mean(vecs_t, axis=0))\n",
                "        else:\n",
                "            vecs.append(np.zeros(w2v.vector_size))\n",
                "    return np.array(vecs)\n",
                "\n",
                "# Carrega modelo Word2Vec.\n",
                "def get_dv2(tokens, model_path=\"models/d2v\", params=None, rebuild=False, save_model=True):\n",
                "\n",
                "    if os.path.exists(model_path) and not rebuild:\n",
                "        return Doc2Vec.load(model_path)\n",
                "\n",
                "    if params is not None:\n",
                "        model = Doc2Vec(\n",
                "            sentences=tokens, vector_size=params[\"vector_size\"], epochs=params[\"epochs\"]\n",
                "        )\n",
                "    else:\n",
                "        model = Doc2Vec(sentences=tokens, workers=15)\n",
                "\n",
                "    if save_model:\n",
                "        if params is not None:\n",
                "            keys = list(params.keys())\n",
                "            keys.sort()\n",
                "            sufix = \"_\".join([key + \"-\" + str(params[key]) for key in keys])\n",
                "        else:\n",
                "            sufix = \"default.model\"\n",
                "        output = \"models/d2v_\" + sufix + \".model\"\n",
                "        model.save(output)\n",
                "\n",
                "    return model\n",
                "\n",
                "# Transforma dados em vetor com o modelo word2vec.\n",
                "def d2v_transform(n_docs, d2v):\n",
                "\n",
                "    return np.array([ d2v.docvecs[v] for v in range(n_docs) ])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "df = df[ (df.p_title.notna()) & (df.p_title.notnull()) ]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "counts = df.cluster_id.value_counts()\n",
                "freqs = [ counts[cid] for cid in df.cluster_id ]\n",
                "df[\"freqs\"] = freqs"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "df[\"freqs\"].head()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "feat_tokens = clean_text(df.p_title.values)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "params = {\n",
                "    \"vector_size\": 100,\n",
                "    \"sg\": 1,\n",
                "    \"epochs\": 5\n",
                "}\n",
                "model = get_w2v(feat_tokens, params=params)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "feats = w2v_transform(feat_tokens, model)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "feats.shape"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Classificação de produtos por categoria.\n",
                "\n",
                "Verificando o desempenho dos classificadores por categoria."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "r = np.random\n",
                "seed = r.randint(0, 2147483647 * 2)\n",
                "\n",
                "\"\"\"\n",
                "classifiers = {\n",
                "    \"RandomForestClassifier\": RandomForestClassifier(n_jobs=10, random_state=seed),\n",
                "    \"LogisticRegression\": LogisticRegression(max_iter=400, multi_class='multinomial', n_jobs=10, random_state=seed),\n",
                "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=seed),\n",
                "    \"KNeighborsClassifier\": KNeighborsClassifier(n_jobs=10),\n",
                "    \"SVC\": SVC(random_state=seed)\n",
                "}\n",
                "\"\"\"\n",
                "classifiers = {\n",
                "    \"RandomForestClassifier\": RandomForestClassifier(n_jobs=10, random_state=seed),\n",
                "    \"LogisticRegression\": LogisticRegression(max_iter=400, multi_class='multinomial', n_jobs=10, random_state=seed),\n",
                "    \"KNeighborsClassifier\": KNeighborsClassifier(n_jobs=10)\n",
                "}"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def avaliation(classifiers, feats, target):\n",
                "\n",
                "    estimators = {}\n",
                "    seed = r.randint(0, 2147483647 * 2)\n",
                "    n_folds = 5\n",
                "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
                "    for alg in classifiers:\n",
                "        \n",
                "        # Validação cruzada.\n",
                "        for train_index, test_index in kf.split(feats):\n",
                "\n",
                "            X_train, X_test = feats[train_index], feats[test_index]\n",
                "            y_train, y_test = target[train_index], target[test_index]\n",
                "            # Clonando o classificador.\n",
                "            clf = clone(classifiers[alg])\n",
                "            # Predizendo \n",
                "            clf.fit(X_train, y_train)\n",
                "            y_pred = clf.predict(X_test)\n",
                "            if alg not in estimators:\n",
                "                estimators[alg] = {}\n",
                "                estimators[alg][\"accs\"] = []\n",
                "                estimators[alg][\"f1s\"] = []\n",
                "            estimators[alg][\"accs\"].append(accuracy_score(y_test, y_pred))\n",
                "            estimators[alg][\"f1s\"].append(f1_score(y_test, y_pred, average=\"macro\"))\n",
                "    \n",
                "        estimators[alg][\"accs\"] = np.array(estimators[alg][\"accs\"])\n",
                "        estimators[alg][\"f1s\"] = np.array(estimators[alg][\"f1s\"])\n",
                "        estimators[alg][\"mean_accs\"] = np.mean(estimators[alg][\"accs\"])\n",
                "        estimators[alg][\"mean_f1\"] = np.mean(estimators[alg][\"f1s\"])\n",
                "        estimators[alg][\"std_accs\"] = np.std(estimators[alg][\"accs\"])\n",
                "        estimators[alg][\"std_f1\"] = np.std(estimators[alg][\"f1s\"])\n",
                "\n",
                "    return estimators\n",
                "\n",
                "#from pprint import pprint\n",
                "#e = avaliation(classifiers, feats, df.cluster_id)\n",
                "#pprint(e)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from sklearn.multiclass import OneVsRestClassifier\n",
                "from sklearn.multioutput import MultiOutputClassifier\n",
                "\n",
                "r = np.random\n",
                "seed = r.randint(0, 2147483647 * 2)\n",
                "\n",
                "\"\"\"\n",
                "target = np.zeros((len(df), len(set(df.cluster_id))))\n",
                "for i in df.cluster_id:\n",
                "    target[i] = 1\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(feats, target)# df.cluster_id)\n",
                "\"\"\"\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(feats, df.cluster_id)\n",
                "\n",
                "#clf = MultiOutputClassifier(LogisticRegression(max_iter=400, multi_class='multinomial', n_jobs=10, random_state=seed))\n",
                "#clf = KNeighborsClassifier(n_jobs=10)\n",
                "#clf = RandomForestRegressor(random_state=seed, n_jobs=10)\n",
                "clf = LogisticRegression(max_iter=400, multi_class='multinomial', n_jobs=10, random_state=seed)\n",
                "\n",
                "print(\"Treinando...\")\n",
                "clf.fit(X_train, y_train)\n",
                "print(\"Predizendo...\")\n",
                "y_pred = clf.predict(X_test)\n",
                "y_pred"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from skmultilearn.adapt import MLkNN\n",
                "from skmultilearn.problem_transform import BinaryRelevance\n",
                "\n",
                "r = np.random\n",
                "seed = r.randint(0, 2147483647 * 2)\n",
                "\n",
                "lgr = LogisticRegression(max_iter=400, multi_class='multinomial', n_jobs=10, random_state=seed)\n",
                "#clf = BinaryRelevance(classifier=lgr, require_dense=[False, True])\n",
                "#clf = MLkNN(k=3)\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(feats, np.array(df.cluster_id))\n",
                "\n",
                "print(\"Treinando...\")\n",
                "clf.fit(X_train, y_train)\n",
                "print(\"Predizendo...\")\n",
                "y_pred = clf.predict(X_test)\n",
                "y_pred"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "df[\"vetores\"] = list(feats.tolist())\n",
                "df[\"vetores\"].head()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "source": [
                "\n",
                "r = np.random\n",
                "seed = r.randint(0, 2147483647 * 2)\n",
                "\n",
                "# Verificando a taxa de acerto pela quantidade de classes.\n",
                "n_fold = 5\n",
                "ids = list(set(df[(df.freqs >= n_fold) & (df.cat_id == 2612)].cluster_id))\n",
                "len(ids)\n",
                "limit = 50\n",
                "for i in range(3, limit):\n",
                "    # Escolhendo um sample de produtos aleatório.\n",
                "    clusters_ids = np.random.choice(ids, i)\n",
                "    set_sample = df.cluster_id.isin(clusters_ids)\n",
                "    target = df[set_sample][\"cluster_id\"].values\n",
                "    vecs = feats[set_sample]\n",
                "    #clf = LogisticRegression(max_iter=400, multi_class='multinomial', n_jobs=10, random_state=seed)\n",
                "    #clf = GradientBoostingClassifier(random_state=seed)\n",
                "    #clf = KNeighborsClassifier(n_jobs=10)\n",
                "    #clf = RandomForestClassifier(random_state=seed, n_jobs=5)\n",
                "    clf = SVC()\n",
                "    print(\"Number of classes: \", i, \"F1: \", np.mean(cross_val_score(clf, vecs, target, cv=n_fold, n_jobs=10, scoring='f1_macro')))\n",
                "    \n",
                "    \"\"\"\n",
                "    # Separando o dado em treino e teste.\n",
                "    X_train, X_test, y_train, y_test = train_test_split(vecs, target, test_size=0.2)\n",
                "    # Classificando o dado.\n",
                "    clf = LogisticRegression(max_iter=400, multi_class='multinomial', n_jobs=10, random_state=seed)\n",
                "    clf.fit(X_train, y_train)\n",
                "    y_pred = clf.predict(X_test)\n",
                "    # Computando F1-Score.\n",
                "    print(f1_score(y_test, y_pred, average=\"macro\"))\n",
                "    \"\"\"\n",
                "\n",
                "\n",
                "    \n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Number of classes:  3 F1:  0.5777777777777778\n",
                        "Number of classes:  4 F1:  0.7430952380952381\n",
                        "Number of classes:  5 F1:  0.6444444444444444\n",
                        "Number of classes:  6 F1:  0.3307142857142857\n",
                        "Number of classes:  7 F1:  0.20619666048237476\n",
                        "Number of classes:  8 F1:  0.23609126984126988\n",
                        "Number of classes:  9 F1:  0.2622222222222222\n",
                        "Number of classes:  10 F1:  0.1823352725705667\n",
                        "Number of classes:  11 F1:  0.3417359307359307\n",
                        "Number of classes:  12 F1:  0.12878417878417878\n",
                        "Number of classes:  13 F1:  0.13743339993339992\n",
                        "Number of classes:  14 F1:  0.19459856382933305\n",
                        "Number of classes:  15 F1:  0.13734236134236133\n",
                        "Number of classes:  16 F1:  0.17965575725444144\n",
                        "Number of classes:  17 F1:  0.12515707821590175\n",
                        "Number of classes:  18 F1:  0.22782330500596756\n",
                        "Number of classes:  19 F1:  0.17627754961088293\n",
                        "Number of classes:  20 F1:  0.17448452781786117\n",
                        "Number of classes:  21 F1:  0.1688008543743838\n",
                        "Number of classes:  22 F1:  0.10451590737305023\n",
                        "Number of classes:  23 F1:  0.09133976225536328\n",
                        "Number of classes:  24 F1:  0.08774921261539508\n",
                        "Number of classes:  25 F1:  0.15970519379610287\n",
                        "Number of classes:  26 F1:  0.08848691383208449\n",
                        "Number of classes:  27 F1:  0.03707326721567381\n",
                        "Number of classes:  28 F1:  0.11528502724581155\n",
                        "Number of classes:  29 F1:  0.08264622255572482\n",
                        "Number of classes:  30 F1:  0.07995118331960438\n",
                        "Number of classes:  31 F1:  0.11216246226222146\n",
                        "Number of classes:  32 F1:  0.09099299698271035\n",
                        "Number of classes:  33 F1:  0.079935715356768\n",
                        "Number of classes:  34 F1:  0.07151312861489631\n",
                        "Number of classes:  35 F1:  0.09884729120023239\n",
                        "Number of classes:  36 F1:  0.0653675903032703\n",
                        "Number of classes:  37 F1:  0.07434096206823479\n",
                        "Number of classes:  38 F1:  0.061915988312708635\n",
                        "Number of classes:  39 F1:  0.05913661315595457\n",
                        "Number of classes:  40 F1:  0.08309646694512048\n",
                        "Number of classes:  41 F1:  0.0810507111439575\n",
                        "Number of classes:  42 F1:  0.05093635809857788\n",
                        "Number of classes:  43 F1:  0.0868549631719997\n",
                        "Number of classes:  44 F1:  0.08020014308836401\n",
                        "Number of classes:  45 F1:  0.0471600658113816\n",
                        "Number of classes:  46 F1:  0.05049651197526237\n",
                        "Number of classes:  47 F1:  0.05081955108758933\n",
                        "Number of classes:  48 F1:  0.06873436993869395\n",
                        "Number of classes:  49 F1:  0.08371899818315631\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "df[df.cluster_id.isin([45222])]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "set(df.cat_id)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.2",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.2 64-bit ('.env': venv)"
        },
        "interpreter": {
            "hash": "7d523c96b21cf24f4470c6693ca6bd0822e9cd1ea6681fac67f9c2c7b59def3d"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}