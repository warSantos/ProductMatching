{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Análise e classificação de produtos do marketplace.\n",
                "### Classificação de produtos pela categoria e distinção de produtos únicos.\n",
                "\n",
                "Neste notebook exploramos diferentes estratégias de ML/DL para classificar produtos em suas categorias, analisar o desempenho dos classificadores sobre base com milhares de róturos e dinstinguí-los entre suas correspondentes variantes."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import os\n",
                "import time\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from scipy.spatial.distance import squareform\n",
                "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
                "from sklearn.metrics import accuracy_score, f1_score\n",
                "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.svm import SVC\n",
                "from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree, ward\n",
                "#from sklearn.cluster import AgglomerativeClustering\n",
                "from sklearn.base import clone\n",
                "from sklearn.metrics import pairwise_distances\n",
                "\n",
                "from gensim.models.fasttext import FastText\n",
                "\n",
                "# Módulos locais\n",
                "\n",
                "from utils.text_clean import clean_text\n",
                "from utils.word2vec import Word2VecModel\n",
                "from utils.doc2vec import Doc2VecModel\n",
                "\n",
                "from utils.clfs import Clfs"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "headers = [\"p_id\", \"p_title\", \"vendor_id\", \"cluster_id\", \"cluster_title\", \"cat_id\", \"cat_title\"]\n",
                "df = pd.read_csv('datasets/pricerunner_aggregate.csv', header=0, names = headers)\n",
                "#df = df[df.cat_id == 2612]\n",
                "df.head()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Construção de atributos (Features)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "df = df[ (df.p_title.notna()) & (df.p_title.notnull()) ]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Atribuindo a cada produto da base um inteiro com a quantidade de nomes\n",
                "# diferentes estão associados ao seu ID (incluindo ele).\n",
                "counts = df.cluster_id.value_counts()\n",
                "freqs = [ counts[cid] for cid in df.cluster_id ]\n",
                "df[\"freqs\"] = freqs"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "feat_tokens = clean_text(df.p_title.values)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "w2v_params = {\n",
                "    \"sentences\": feat_tokens,\n",
                "    \"vector_size\": 100,\n",
                "    \"sg\": 0,\n",
                "    \"window\": 6,\n",
                "    \"epochs\": 10,\n",
                "    \"workers\": 10\n",
                "}\n",
                "\n",
                "w2v = Word2VecModel(feat_tokens, params=w2v_params)\n",
                "\n",
                "d2v_params = {\n",
                "    \"documents\":  feat_tokens,\n",
                "    \"vector_size\": 100,\n",
                "    \"dm\": 0,\n",
                "    \"window\": 6,\n",
                "    \"epochs\": 10,\n",
                "    \"dbow_words\": 1,\n",
                "    \"workers\": 10\n",
                "}\n",
                "\n",
                "d2v = Doc2VecModel(feat_tokens, params=d2v_params)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "representacoes = {}\n",
                "representacoes[\"word2vec\"] = w2v.transform(feat_tokens)\n",
                "representacoes[\"doc2vec\"] = d2v.transform(len(feat_tokens))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Classificação de produtos por categoria.\n",
                "\n",
                "Verificando o desempenho dos classificadores por categoria."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "r = np.random\n",
                "seed = r.randint(0, 2147483647 * 2)\n",
                "\n",
                "classifiers = {\n",
                "    \"RandomForestClassifier\": RandomForestClassifier(n_jobs=10, random_state=seed),\n",
                "    \"LogisticRegression\": LogisticRegression(max_iter=400, multi_class='multinomial', n_jobs=10, random_state=seed),\n",
                "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=seed),\n",
                "    \"KNeighborsClassifier\": KNeighborsClassifier(n_jobs=10),\n",
                "    \"SVC\": SVC(random_state=seed)\n",
                "}\n",
                "\n",
                "\"\"\"\n",
                "classifiers = {\n",
                "    \"RandomForestClassifier\": RandomForestClassifier(n_jobs=10, random_state=seed),\n",
                "    \"LogisticRegression\": LogisticRegression(max_iter=2000, multi_class='multinomial', n_jobs=10, random_state=seed),\n",
                "    \"KNeighborsClassifier\": KNeighborsClassifier(n_jobs=10)\n",
                "}\n",
                "\"\"\"\n",
                "\n",
                "\"\"\"\n",
                "classifiers = {\n",
                "    \"LogisticRegression\": LogisticRegression(max_iter=2000, multi_class='multinomial', n_jobs=10, random_state=seed),\n",
                "    \"KNeighborsClassifier\": KNeighborsClassifier(n_jobs=10)\n",
                "}\n",
                "\"\"\"\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Avaliando diferentes classificadores para classificação dos produtos em suas categorias."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "pipeline = Clfs()\n",
                "\n",
                "results = []\n",
                "scores_rep = {}\n",
                "for rep in representacoes:\n",
                "    scores_clfs = pipeline.fast_avaliation(classifiers, representacoes[rep], df.cat_id)\n",
                "    for clf in scores_clfs:\n",
                "        results.append([rep, clf, scores_clfs[clf][\"mean_f1\"], scores_clfs[clf][\"std_f1\"]])\n",
                "\n",
                "cat_results = pd.DataFrame(results, columns=[\"Rep\", \"Clf\", \"MeanF1\", \"StdF1\"])\n",
                "timestamp = time.strftime(\"%Y-%m-%d - %H:%M:%S\")\n",
                "cat_results.to_csv(f'tables/f1_rep_{timestamp}.csv', index=False)\n",
                "cat_results.head(10)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Verificação dos classificadores para o problema PU.\n",
                "\n",
                "### Análise do desempenho dos classificadores conforme mais produtos são adicionados a classificação."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\n",
                "r = np.random\n",
                "seed = r.randint(0, 2147483647 * 2)\n",
                "\n",
                "# Verificando a taxa de acerto pela quantidade de classes.\n",
                "#n_folds = 5\n",
                "limit = 30\n",
                "results = {}\n",
                "for n_class in range(3, 11):\n",
                "    ids = list(set(df[(df.freqs >= n_class) & (df.cat_id == 2622)].cluster_id))\n",
                "    results[n_class] = {}\n",
                "    for i in range(3, limit):\n",
                "        results[n_class][i] = {}\n",
                "        # Escolhendo um sample de produtos aleatório da base.\n",
                "        clusters_ids = np.random.choice(ids, i)\n",
                "        set_sample = df.cluster_id.isin(clusters_ids)\n",
                "        # Para cada representação.\n",
                "        for rep in representacoes:\n",
                "            target = df[set_sample][\"cluster_id\"].values\n",
                "            features = representacoes[rep][set_sample]\n",
                "            results[n_class][i][rep] = pipeline.fast_avaliation(classifiers, features, target, n_folds=n_class)\n",
                "\n",
                "from pprint import pprint\n",
                "\n",
                "pprint(results)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\n",
                "import json\n",
                "\n",
                "with open('tables/f1_classes.json', 'w') as fd:\n",
                "    json.dump(results, fd)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def plot_graphs(results):\n",
                "\n",
                "    total_class = len(results.keys())\n",
                "    values_plot = {}\n",
                "\n",
                "    # Para cada limite com classe.\n",
                "    for n_class in results:\n",
                "        values_plot[n_class] = {}\n",
                "        # Para cada iteração.\n",
                "        for it in results[n_class]:\n",
                "            # Para cada representação.\n",
                "            for rep in results[n_class][it]:\n",
                "                if rep not in values_plot[n_class]:\n",
                "                    values_plot[n_class][rep] = {}\n",
                "                # Para cada classificador.\n",
                "                for clf in results[n_class][it][rep]:\n",
                "                    if clf not in values_plot[n_class][rep]:\n",
                "                        values_plot[n_class][rep][clf] = []\n",
                "                    mean_f1 = results[n_class][it][rep][clf][\"mean_f1\"]\n",
                "                    values_plot[n_class][rep][clf].append(mean_f1)\n",
                "\n",
                "    fig, axes = plt.subplots(4,2, figsize=(14,18))\n",
                "    for n_class, index in zip(values_plot, range(total_class)):\n",
                "        col = index % 2\n",
                "        line = index // 2\n",
                "        for rep in values_plot[n_class]:\n",
                "            for clf in values_plot[n_class][rep]:\n",
                "                y = values_plot[n_class][rep][clf]\n",
                "                x = list(range(3, limit))\n",
                "                label = rep+' '+clf\n",
                "                axes[line, col].plot(x, y, label=label)\n",
                "        axes[line, col].legend()\n",
                "        axes[line, col].set_ylim((0,1))\n",
                "        axes[line, col].set_xlabel(\"Number of Classes\", fontsize=16)\n",
                "        axes[line, col].set_ylabel(\"F1 (%)\", fontsize=16)\n",
                "        axes[line, col].set_title(\"Class with \"+str(n_class), fontsize=18)\n",
                "        axes[line, col].tick_params(axis='x', labelsize=16)\n",
                "        axes[line, col].tick_params(axis='y', labelsize=16)\n",
                "        axes[line, col].grid()\n",
                "    fig.tight_layout()\n",
                "    plt.savefig('graphs/f1_classes.pdf')\n",
                "\n",
                "\n",
                "plot_graphs(results)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Agrupamento de PUs por categoria\n",
                "\n",
                "### Para cada categoria inicial da base de dados vamos agrupar os produtos únicos com a técnica de clustering aglomerativo. Utilizamos essa técnica isoladamente por categoria para que essa escale com maior facilidade conforme aumenta o volume dos dados."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "cat_ids = set(df.cat_id)\n",
                "\n",
                "dists = {}\n",
                "for cat_id in cat_ids:\n",
                "    indexes = df.cat_id.isin([cat_id])\n",
                "    feats = representacoes[\"word2vec\"][indexes]\n",
                "    dist = pairwise_distances(feats, metric=\"cosine\", n_jobs=10)\n",
                "    np.fill_diagonal(dist,0)\n",
                "    dists[cat_id] = squareform(dist)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def plot_dists(dists):\n",
                "\n",
                "    cat_ids = list(dists.keys())\n",
                "    total = len(cat_ids)\n",
                "    fig, ax = plt.subplots(figsize=(14,10))\n",
                "    for i in range(total):\n",
                "        col = i % 2\n",
                "        line = i // 2\n",
                "        ax = plt.subplot(3, 4, i+1)\n",
                "        x = list(range(dists[cat_ids[i]].shape[0]))\n",
                "        y = np.copy(dists[cat_ids[i]])\n",
                "        y.sort()\n",
                "        label_cat = df[df.cat_id == cat_ids[i]].iloc[0][\"cat_title\"]\n",
                "        plt.plot(x, y, label=label_cat)\n",
                "        plt.grid()\n",
                "        plt.xticks(fontsize=16)\n",
                "        plt.yticks(fontsize=16)\n",
                "        plt.xlabel(\"Comparasons\", fontsize=16)\n",
                "        plt.ylabel(\"Distances\", fontsize=16)\n",
                "        plt.tight_layout()\n",
                "        plt.legend()\n",
                "\n",
                "plot_dists(dists)\n",
                "        \n",
                "        "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "from sklearn.metrics import confusion_matrix\n",
                "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
                "\n",
                "def _make_cost_m(cm):\n",
                "    s = np.max(cm)\n",
                "    return (- cm + s)\n",
                "\n",
                "def cluster_accuracy(labels, predicted_labels):\n",
                "    cm = confusion_matrix(labels, predicted_labels)\n",
                "    indexes = linear_assignment(_make_cost_m(cm))\n",
                "    js = [e[1] for e in sorted(indexes, key=lambda x: x[0])]\n",
                "    cm2 = cm[:, js]\n",
                "    acc = np.trace(cm2) / np.sum(cm2)\n",
                "    return acc\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "for cat_id in dists:\n",
                "    #clu = AgglomerativeClustering(affinity=\"precomputed\", linkage=\"complete\")\n",
                "    #clu.fit(dists[cat_id])\n",
                "    Z = ward(dists[cat_id])\n",
                "    labels = cut_tree(Z, height=0.2)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.2",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.2 64-bit ('.env': venv)"
        },
        "interpreter": {
            "hash": "7d523c96b21cf24f4470c6693ca6bd0822e9cd1ea6681fac67f9c2c7b59def3d"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}